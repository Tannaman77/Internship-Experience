{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "import glob\n",
    "import h5py\n",
    "import jax\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pyscf\n",
    "\n",
    "from flax import linen as nn\n",
    "from glob import glob\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from pyscf import gto, scf\n",
    "from pyscf.dft import numint\n",
    "\n",
    "\n",
    "from typing import Callable, Sequence, Optional, NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid(NamedTuple):\n",
    "    coords : Array\n",
    "    weights : Array\n",
    "\n",
    "def integrate(grid: Grid, vals = Array, axes=(0,axis):\n",
    "    return jnp.tensordot(grid.weights,vals, axes=(0,axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_file(path):\n",
    "    all_coords = []\n",
    "    all_weights = []\n",
    "    all_rho = []\n",
    "    all_GradR = []\n",
    "    all_lda = []\n",
    "    all_pbe = []\n",
    "    \n",
    "    with h5py.File(path, 'r') as file:\n",
    "        num_entries = len(file['coords'])  # Assuming all datasets have the same length\n",
    "        \n",
    "        for x in range(num_entries):\n",
    "            all_coords.append(np.array(file['coords'][x]))\n",
    "            all_weights.append(np.array(file['weights'][x]))\n",
    "            all_rho.append(np.array(file['rho'][x]))\n",
    "            all_GradR.append(np.array(file['grad_rho'][x]))\n",
    "            all_lda.append(np.array(file['exc_lda'][x]))\n",
    "            all_pbe.append(np.array(file['exc_pbe'][x]))\n",
    "    \n",
    "    return [load_file(data)]\n",
    "\n",
    "def load_data(folder_path):\n",
    "    paths = glob.glob(folder_path + '/*.h5')\n",
    "    return [load_file(path) for path in paths]\n",
    "\n",
    "def separate_data(data):\n",
    "    return zip(*data)\n",
    "\n",
    "# Example usage:\n",
    "data_folder = \"/Users/corneliussalonis/Research/SNSP_23/MLtut/cornelius_data\"\n",
    "data = load_data(data_folder)\n",
    "separated_data = separate_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    with h5py.File(path,'r') as file:\n",
    "        for x in len(path):\n",
    "            all_coords[x] = np.array(file['coords'])\n",
    "            all_weights[x]= np.array(file['weights'])\n",
    "            all_rho[x] = np.array(file['rho'])\n",
    "            all_GradR[x] = np.array(file['grad_rho'])\n",
    "            all_lda[x] = np.array(file['exc_lda'])\n",
    "            all_pbe[x]= np.array(file['exc_pbe'])\n",
    "            #grid = Grid(all_coords,all_weights)\n",
    "            #inputs = FunctionalInputs(grid,all_rho, all_GradR)\n",
    "    \n",
    "def load_data(folder_path):\n",
    "    paths = glob(folder_path)\n",
    "    return [load_file(path) for path in paths]\n",
    "\n",
    "def seperate_data(data):\n",
    "    return zip(*data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data1 \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/corneliussalonis/Research/SNSP_23/MLtut/cornelius_data/*-gauss_chebyshev*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data1\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(folder_path):\n\u001b[0;32m---> 14\u001b[0m     paths \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [load_file(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "data1 = load_data('/Users/corneliussalonis/Research/SNSP_23/MLtut/cornelius_data/*-gauss_chebyshev*')\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 \n",
    "for x in range(len(path)):\n",
    "    with h5py.File(path[x], 'r') as file:\n",
    "    #print(file.keys())\n",
    "        all_coords[f'Coords of {path[x]}'] = np.array(file['coords'])\n",
    "        trial_weights = np.array(file['weights'])\n",
    "\n",
    "        trial_rho = np.array(file['rho'])\n",
    "    #trial_rho = jnp.broadcast_to(trial_rho / 2, (2, *trial_rho.shape))\n",
    "\n",
    "        Tgrad_rho = np.array(file['grad_rho'])\n",
    "    #Tgrad_rho = jnp.broadcast_to(Tgrad_rho, (2, *Tgrad_rho.shape))\n",
    "\n",
    "        exc_lda = np.array(file['exc_lda'])\n",
    "        exc_pbe = np.array(file['exc_pbe'])\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_rho = jnp.broadcast_to(trial_rho / 2, (2, *trial_rho.shape))\n",
    "#fixed_grho = jnp.broadcast_to(Tgrad_rho, (2, *Tgrad_rho.shape))\n",
    "#norm2 = jnp.sum(Tgrad_rho**2, axis = -1)\n",
    "#spin2 = jnp.sum(Tgrad_rho.sum(axis = 0, keepdims = True)**2, axis = -1)\n",
    "#feature_list = [trial_rho, Tgrad_rho,norm2,spin2]\n",
    "#print(fixed_grho.shape,fixed_rho.shape)\n",
    "#new = jnp.concatenate(feature_list, axis=0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array = jax.Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid(NamedTuple):\n",
    "    coords : Array\n",
    "    weights : Array\n",
    "\n",
    "def integrate(grid: Grid, vals = Array, axis: int = 0)-> Array:\n",
    "    return jnp.tensordot(grid.weights, vals, axes=(0,axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalInputs(NamedTuple):\n",
    "    grid: Grid\n",
    "    rho: Array\n",
    "    grad_rho: Optional[Array] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_array(inputs: FunctionalInputs):\n",
    "    _, rho, grad_rho = inputs\n",
    "\n",
    "    if grad_rho is None:\n",
    "        feature_list = [rho]\n",
    "\n",
    "    else:\n",
    "        #grad_rho = grad_rho.transpose()\n",
    "        grad_rho_norm = jnp.sum(grad_rho**2, axis=-1)\n",
    "        feature_list = [rho,grad_rho_norm]\n",
    "    return jnp.stack(feature_list, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardFeedNN(nn.Module):\n",
    "    \n",
    "    layer_widths: Sequence[int]\n",
    "    out_features = 1\n",
    "    activate : Callable[[Array],Array] = jax.nn.gelu\n",
    "    squash_offset: float = 1e-4\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,inputs: FunctionalInputs):\n",
    "        \n",
    "        x = build_input_array(inputs)\n",
    "\n",
    "        h = jnp.log(jnp.abs(x)+self.squash_offset)\n",
    "        h = nn.Dense(features = self.layer_widths[0])(h)\n",
    "        h = jnp.tanh(h)\n",
    "\n",
    "        for feature in self.layer_widths:\n",
    "            h = nn.Dense(features = feature)(h)\n",
    "            h = nn.LayerNorm()(h)\n",
    "            h = self.activate(h)\n",
    "            \n",
    "        h = nn.Dense(features = self.out_features)(h)\n",
    "        return 2 * jax.nn.sigmoid(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(coords = trial_coords, weights = trial_weights)\n",
    "inputs = FunctionalInputs(grid, rho = trial_rho, grad_rho = Tgrad_rho)\n",
    "\n",
    "#fxc = ForwardFeedNN(layer_widths= [256,256,256])\n",
    "\n",
    "#key = jax.random.PRNGKey(16)\n",
    "#params = fxc.init(key,inputs)\n",
    "grid.coords.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.rho.shape, inputs.grad_rho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = build_input_array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = ForwardFeedNN(layer_widths=(128,128))\n",
    "key = jax.random.PRNGKey(42)\n",
    "params = fxc.init(key, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc = fxc.apply(params,inputs)\n",
    "#exc.shape\n",
    "(grid.weights.shape, grid.coords.shape, trial_rho.shape, exc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate(grid, trial_rho * exc.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.xlabel('Distance from Nucleus')\n",
    "plt.ylabel('Exchange Correlation Energy')\n",
    "plt.scatter(trial_coords,exc_lda)\n",
    "plt.scatter(trial_coords,exc, c = 'r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dexc = jnp.sum(exc_lda)\n",
    "Dexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cs_fun(params, Texc):\n",
    "#     Pexc = integrate(grid, trial_rho * exc.squeeze())\n",
    "#     return jnp.mean((Texc-Pexc)**2)\n",
    "\n",
    "# cs_fun(params, exc_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def cost_one_input(params, inputs, target_exc):\n",
    "    exc = fxc.apply(params, inputs).squeeze()\n",
    "    return integrate(inputs.grid, (exc - target_exc)**2)\n",
    "\n",
    "@jax.value_and_grad\n",
    "def cost_batch(params, inputs: Sequence[FunctionalInputs], target_excs: Sequence[Array]):\n",
    "\n",
    "    batch_size = len(inputs)\n",
    "    mean_cost = 0.0\n",
    "\n",
    "    for input, target in zip(inputs, target_excs):\n",
    "        mean_cost += cost_one_input(params, input, target) / batch_size\n",
    "\n",
    "    return mean_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cost function is integrated mean squared error between the predicted and true values of the output\n",
    "\n",
    "$$ \\texttt{cost} = \\int d^3 x \\; (\\epsilon ^{NN} _{xc} - \\epsilon ^{\\text{target}} _{xc}) ^ 2$$\n",
    "\n",
    "averaged over the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "\n",
    "    with h5py.File(path, 'r') as file:\n",
    "\n",
    "        coords = np.array(file['coords'])\n",
    "        weights = np.array(file['weights'])\n",
    "\n",
    "        rho = np.array(file['rho'])\n",
    "\n",
    "        grad_rho = np.array(file['grad_rho'])\n",
    "\n",
    "        exc = np.array(file['exc_lda'])\n",
    "\n",
    "    grid = Grid(coords, weights)\n",
    "    inputs = FunctionalInputs(grid, rho, grad_rho)\n",
    "\n",
    "    return inputs, exc\n",
    "\n",
    "def load_data(folder_path):\n",
    "    paths = glob(folder_path + '/*.h5')\n",
    "    return [load_file(path) for path in paths]\n",
    "\n",
    "def separate_data(data):\n",
    "\n",
    "    # data is a list of tuples\n",
    "    # this trick separates the inputs and exc (targets)\n",
    "    # example: inputs, targets = separate_data(data)\n",
    "\n",
    "    return zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('./cornelius_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) # loaded 19 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super important - train-test split\n",
    "train_data = data[:16]\n",
    "test_data = data[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_batches(data, batch_size):\n",
    "    return [data[i:i+batch_size] for i in range(0, len(data), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = divide_into_batches(train_data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs, test_targets = separate_data(batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_one_input(params, test_inputs[0], test_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, grad = cost_batch(params, test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cost = jax.value_and_grad(cs_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cost(params, Dexc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_param(params,Dexc,lr = .001):\n",
    "    cost, grad = grad_cost(params,Dexc)\n",
    "    params = params - (lr * grad)\n",
    "    return params, cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for n in range(1000):\n",
    "    params, cost = update_param(params,Dexc)\n",
    "    costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
